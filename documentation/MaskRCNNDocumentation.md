# Mask R-CNN Documentation

## Requirements

* 

## Data

### Kidney Raw Data

This work utilized a dataset of human kidney whole slide images provided by the HuBMAP Consortium, which is now available at [the HuBMAP Data Portal](https://portal.hubmapconsortium.org/search?origin_sample.mapped_organ[0]=Kidney%20%28Left%29&origin_sample.mapped_organ[1]=Kidney%20%28Right%29&group_name[0]=Vanderbilt%20TMC&entity_type[0]=Dataset). The raw kidney image data was generated by the BIOmolecular Multimodal Imaging Center (BIOMIC) at Vanderbilt University. (See [BIOMIC's page](https://medschool.vanderbilt.edu/biomic/) for more information.) This dataset is composed of 13 samples, each with multiple images that correspond to different microscopy types. All samples include PAS stain images, and many include imaging mass spectrometry as well. In addition, this dataset provides information on where the sample was positioned within the kidney and whether it was taken from a left or right kidney, which is vital information for the HuBMAP objective.

[Kidney Raw Data](https://drive.google.com/drive/folders/14aLxPR9LlzdWXPomAX1moqL0UnRm_RbW?usp=sharing)

## Algorithm

The Mask RCNN algorithm is built upon the Faster RCNN algorithm, but it employs an instance segmentation extension that allows prediction of segmentation masks for each annotation. Rather than relying on the rectangular regions of the Faster RCNN algorithm for outputting detection boxes, the Mask RCNN provides a classification of ”Glomeruli” or ”Non-Glomeruli” to each pixel in the original image. This allows the resulting annotations to be any shape describable by pixels and enables the creation of binary mask overlays for use on the original image.
![Mask R-CNN Diagram](https://github.com/cns-iu/ccf-research-ftu/blob/master/images/MaskRCNNdiagram.jpg)

## Workflow
![Mask R-CNN Pipeline](https://github.com/cns-iu/ccf-research-ftu/blob/master/images/pipeline%20images/Mask%20RCNN%20Pipeline.jpg)
### Getting Started

### Kidney Data Preprocessing and Manual Annotation Data

From these 13 samples, a subset of six PAS  stain images were used to generate the ML training dataset. This glomeruli detection training dataset of manually generated glomeruli annotations was created by four users who marked areas corresponding to glomeruli on the six images. All users performed their annotations on laptops that included Windows 10 OS, a trackpad, and 1920x1080 screen resolution. Half of the users made annotations with the software QuPath and its brush tool, while the other half utilized ImageJ with its oval tool. 

[Manual Glomeruli Annotation Data - Accessible to IU Users Only](https://drive.google.com/drive/folders/1YdOvkIWyWBOc-zSxClC1kVwST8YxVKXc?usp=sharing)

### Training

### Segmentation

## Results
